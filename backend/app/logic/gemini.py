import os
import json
from typing import Optional, List
from dotenv import load_dotenv
import google.generativeai as genai

# --- 1. í™˜ê²½ ì„¤ì • ---
load_dotenv()
API_KEY = os.getenv("GOOGLE_API_KEY")

# [ìˆ˜ì •] ëª¨ë¸ ëª©ë¡ í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ (.env íŒŒì¼ì— ì •ì˜ëœ ëŒ€ë¡œ)
# ìš°ì„ ìˆœìœ„ëŒ€ë¡œ ì½¤ë§ˆë¡œ ë‚˜ì—´ëœ ë¬¸ìì—´ì„ ì½ì–´ì˜µë‹ˆë‹¤.
FAST_MODELS_STR = os.getenv("GEMINI_FAST_MODELS", "gemini-2.5-flash")
QUALITY_MODELS_STR = os.getenv("GEMINI_QUALITY_MODELS", "gemini-2.5-flash")

# ì½¤ë§ˆë¡œ ë¶„ë¦¬í•˜ì—¬ ë¦¬ìŠ¤íŠ¸ë¡œ ë§Œë“­ë‹ˆë‹¤.
FAST_MODEL_LIST = [m.strip() for m in FAST_MODELS_STR.split(',') if m.strip()]
QUALITY_MODEL_LIST = [m.strip() for m in QUALITY_MODELS_STR.split(',') if m.strip()]


# --- 2. Gemini ëª¨ë¸ ì„¤ì • ---
model_fast = None     # [ìˆ˜ì •] ë¹ ë¥¸ í”¼ë“œë°±ìš© ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤
model_quality = None  # [ìˆ˜ì •] ì¢…í•© ìš”ì•½ìš© ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤

# [ì‹ ê·œ] ëª¨ë¸ ì´ˆê¸°í™” í—¬í¼ í•¨ìˆ˜
def initialize_model_from_list(
    model_list: List[str], 
    generation_config: dict, 
    safety_settings: list
) -> Optional[genai.GenerativeModel]:
    """
    ì œê³µëœ ëª¨ë¸ ì´ë¦„ ëª©ë¡ì„ ìˆœíšŒí•˜ë©°
    ê°€ì¥ ë¨¼ì € ì„±ê³µì ìœ¼ë¡œ ì´ˆê¸°í™”ë˜ëŠ” ëª¨ë¸ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    if not API_KEY:
        print("[ERROR] GOOGLE_API_KEYê°€ .env íŒŒì¼ì— ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return None
        
    for model_name in model_list:
        try:
            model = genai.GenerativeModel(
                model_name,
                safety_settings=safety_settings,
                generation_config=generation_config,
            )
            print(f"[INFO] ëª¨ë¸ ì´ˆê¸°í™” ì„±ê³µ: {model_name}")
            return model
        except Exception as e:
            print(f"[WARN] ëª¨ë¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {model_name} (ì˜¤ë¥˜: {e}). ë‹¤ìŒ ëª¨ë¸ì„ ì‹œë„í•©ë‹ˆë‹¤...")
    
    print(f"[ERROR] ëª©ë¡ì— ìˆëŠ” ëª¨ë¸ì„ ì´ˆê¸°í™”í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤: {model_list}")
    return None

# API í‚¤ê°€ ìˆì„ ê²½ìš°ì—ë§Œ ëª¨ë¸ ì„¤ì •ì„ ì‹œë„í•©ë‹ˆë‹¤.
if API_KEY:
    genai.configure(api_key=API_KEY)

    safety_settings = [
        {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_NONE"},
        {"category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_NONE"},
        {"category": "HARM_CATEGORY_SEXUALLY_EXPLICIT", "threshold": "BLOCK_NONE"},
        {"category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_NONE"},
    ]

    # JSON ì‘ë‹µì„ ìœ„í•œ ê³µí†µ ì„¤ì •
    generation_config = {
        "temperature": 0.7,
        "response_mime_type": "application/json",
    }

    # [ìˆ˜ì •] ë¹ ë¥¸ ëª¨ë¸ê³¼ í’ˆì§ˆ ëª¨ë¸ì„ ë³„ë„ë¡œ ì´ˆê¸°í™”
    print(f"[INFO] ë¹ ë¥¸ í”¼ë“œë°± ëª¨ë¸ ì´ˆê¸°í™” ì‹œë„ (ëª©ë¡: {FAST_MODEL_LIST})...")
    model_fast = initialize_model_from_list(
        FAST_MODEL_LIST, generation_config, safety_settings
    )
    
    print(f"[INFO] ì¢…í•© ìš”ì•½ ëª¨ë¸ ì´ˆê¸°í™” ì‹œë„ (ëª©ë¡: {QUALITY_MODEL_LIST})...")
    model_quality = initialize_model_from_list(
        QUALITY_MODEL_LIST, generation_config, safety_settings
    )
else:
    print("[ERROR] GOOGLE_API_KEYë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.")


# --- 3. AI í”¼ë“œë°± ìƒì„± í•¨ìˆ˜ ---

# [ìˆ˜ì •] get_conversational_feedback í•¨ìˆ˜ (extra_contextê°€ í¬í•¨ëœ ìµœì¢… ë²„ì „ë§Œ ë‚¨ê¹€)
async def get_conversational_feedback(
    exercise_name: str,
    rep_counter: int,
    stage: str,
    body_profile: Optional[dict] = None,
    real_time_analysis: Optional[dict] = None,
    angle: Optional[float] = None,
    history: Optional[List[str]] = None,
    extra_context: Optional[dict] = None,  # ğŸ‘ˆ ì¶”ê°€ëœ íŒŒë¼ë¯¸í„°
) -> dict:
    """
    [ìˆ˜ì •] 'ë¹ ë¥¸ í”¼ë“œë°±' ëª¨ë¸(model_fast)ì„ ì‚¬ìš©í•˜ì—¬ ì •í™•ë„ì™€ í”¼ë“œë°±ì„ JSONìœ¼ë¡œ ìš”ì²­í•©ë‹ˆë‹¤.
    """
    # [ìˆ˜ì •] model_fast ì¸ìŠ¤í„´ìŠ¤ë¥¼ ì‚¬ìš©í•˜ë„ë¡ ë³€ê²½
    if not model_fast:
        return {"accuracy": 0, "feedback": "âš ï¸ Gemini 'FAST' ëª¨ë¸ì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."}

    profile_section = f"* ì‚¬ìš©ìì˜ ì²´í˜• ë¶„ì„ ì •ë³´ (ì •ì  ë°ì´í„°):\n{body_profile}\n" if body_profile else ""
    analysis_section = f"* ì´ë²ˆ ì„¸íŠ¸ì˜ ì‹¤ì‹œê°„ ì›€ì§ì„/íˆìŠ¤í† ë¦¬ (ë™ì  ë°ì´í„°):\n{real_time_analysis}\n" if real_time_analysis else ""
    extra_section = f"* ì¶”ê°€ ë§¥ë½(í‘œì‹œëª…/ì„¸íŠ¸/íƒ€ê¹ƒ):\n{extra_context}\n" if extra_context else ""

    # í‘œì‹œìš© í•œê¸€ ì´ë¦„ ìš°ì„  ì‚¬ìš©
    disp = (extra_context or {}).get("exercise_display_name") or exercise_name
    set_idx = (extra_context or {}).get("set_index")
    total_sets = (extra_context or {}).get("total_sets")
    target_reps = (extra_context or {}).get("target_reps")

    prompt = f"""
    ë‹¹ì‹ ì€ í•œêµ­ì–´ë¡œ ë‹µí•˜ëŠ” ì „ë¬¸ AI í¼ìŠ¤ë„ íŠ¸ë ˆì´ë„ˆì…ë‹ˆë‹¤.
    ì•„ë˜ì˜ ì •ì /ë™ì /ì¶”ê°€ ë§¥ë½ì„ ì°¸ì¡°í•˜ë˜, ê·¸ëŒ€ë¡œ ë³µë¶™í•˜ì§€ ë§ê³  **ì¢…í•© íŒë‹¨**ì„ ì œê³µí•˜ì„¸ìš”.

    {profile_section}
    {analysis_section}
    {extra_section}

    * í˜„ì¬ ìš´ë™ ì •ë³´:
    - ìš´ë™(í‘œì‹œëª…): {disp}
    - ìš´ë™(ë‚´ë¶€ID): {exercise_name}
    - ë‹¨ê³„: {stage}
    - ë°˜ë³µ íšŸìˆ˜(ì‹¤í–‰): {rep_counter}
    - ëª©í‘œ ë°˜ë³µìˆ˜(ì„¸íŠ¸ë‹¹): {target_reps}
    - í˜„ì¬ ì„¸íŠ¸/ì´ ì„¸íŠ¸: {set_idx}/{total_sets}

    * JSON ì¶œë ¥ ê·œì¹™:
    1) "accuracy": 0~100 ì •ìˆ˜
    2) "feedback": **70ì ì´ë‚´ í•œêµ­ì–´**ë¡œ í•µì‹¬ë§Œ ìì—°ìŠ¤ëŸ½ê²Œ (íŠ¹ì • ì§€í‘œ ë‹¨ì–´ ì§ì¸ìš© ì§€ì–‘)
    3) ì„ íƒ: "tips": ["ì§§ì€ íŒ"...], "risk_level": "low|mid|high"
    """

    try:
        # [ìˆ˜ì •] model_fast.generate_content_async ì‚¬ìš©
        resp = await model_fast.generate_content_async(prompt)
        try:
            result = json.loads(resp.text)
        except Exception:
            print(f"[WARN] Gemini ì‘ë‹µì´ JSON í˜•ì‹ì´ ì•„ë‹˜: {resp.text}")
            result = {"accuracy": 0, "feedback": "âš ï¸ AI ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨"}
        return result
    except Exception as e:
        print(f"--- GEMINI API ERROR (FAST) ---\nError: {e}\n--------------------------")
        if "resp" in locals() and hasattr(resp, "prompt_feedback"):
            print(f"Prompt Feedback: {resp.prompt_feedback}")
        return {"accuracy": 0, "feedback": "âš ï¸ AI í”¼ë“œë°± ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."}
    

async def get_overall_feedback(set_results: list[dict]) -> dict:
    """
    [ìˆ˜ì •] 'ì¢…í•© ìš”ì•½' ëª¨ë¸(model_quality)ì„ ì‚¬ìš©í•˜ì—¬
    ì „ì²´ì ì¸ ìš´ë™ í’ˆì§ˆ, ìì„¸ ì•ˆì •ì„±, í–¥ìƒ í¬ì¸íŠ¸ë¥¼ ì¢…í•©ì ìœ¼ë¡œ í‰ê°€.
    """
    # [ìˆ˜ì •] model_quality ì¸ìŠ¤í„´ìŠ¤ë¥¼ ì‚¬ìš©í•˜ë„ë¡ ë³€ê²½
    if not model_quality:
        return {"overall_feedback": "âš ï¸ Gemini 'QUALITY' ëª¨ë¸ì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."}

    prompt = f"""
    ë‹¹ì‹ ì€ í”¼íŠ¸ë‹ˆìŠ¤ ì „ë¬¸ê°€ AI íŠ¸ë ˆì´ë„ˆì…ë‹ˆë‹¤.
    ì•„ë˜ëŠ” ì‚¬ìš©ìì˜ ê° ì„¸íŠ¸ë³„ ìš´ë™ ë¶„ì„ ê²°ê³¼ì…ë‹ˆë‹¤.
    ì´ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì „ì²´ ìš´ë™ì— ëŒ€í•œ ì¢…í•© í”¼ë“œë°±ì„ ì‘ì„±í•˜ì„¸ìš”.

    ë°ì´í„°:
    {json.dumps(set_results, ensure_ascii=False, indent=2)}

    ì‘ì„± ê·œì¹™:
    1. ì „ì²´ì ì¸ ìš´ë™ ìˆ˜í–‰ í’ˆì§ˆì„ ìš”ì•½í•˜ì„¸ìš” (ì •í™•ë„, ì•ˆì •ì„±, í”¼ë¡œë„ ë“±).
    2. ì‚¬ìš©ìì˜ ê°œì„ ì  2~3ê°€ì§€ë¥¼ ì§§ê³  ëª…í™•í•˜ê²Œ ì œì‹œí•˜ì„¸ìš”.
    3. ë¬¸ì¥ì€ ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´ë¡œ ì‘ì„±í•˜ê³ , 200ì ì´ë‚´ë¡œ ë§ˆë¬´ë¦¬í•˜ì„¸ìš”.
    4. JSON í˜•ì‹ìœ¼ë¡œ ì¶œë ¥:
    {{
    "overall_feedback": "ë¬¸ì¥",
    "summary_accuracy": <í‰ê·  ì •í™•ë„>,
    "improvement_tips": ["tip1", "tip2", ...]
    }}
    """
    try:
        # [ìˆ˜ì •] model_quality.generate_content_async ì‚¬ìš©
        resp = await model_quality.generate_content_async(prompt)
        return json.loads(resp.text)
    except Exception as e:
        print(f"--- GEMINI API ERROR (QUALITY) ---\nError: {e}\n--------------------------")
        if "resp" in locals() and hasattr(resp, "prompt_feedback"):
            print(f"Prompt Feedback: {resp.prompt_feedback}")
        return {"overall_feedback": "âš ï¸ ì¢…í•© í”¼ë“œë°± ìƒì„± ì‹¤íŒ¨"}
