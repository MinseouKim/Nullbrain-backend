import os
import json
from typing import Optional, List, Any, Dict
from dotenv import load_dotenv
import google.generativeai as genai

# --- 1. í™˜ê²½ ì„¤ì • ---
load_dotenv()
API_KEY = os.getenv("GOOGLE_API_KEY")

# [ìˆ˜ì •] ëª¨ë¸ ëª©ë¡ í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ (.env íŒŒì¼ì— ì •ì˜ëœ ëŒ€ë¡œ)
FAST_MODELS_STR = os.getenv("GEMINI_FAST_MODELS", "gemini-2.5-flash")
QUALITY_MODELS_STR = os.getenv("GEMINI_QUALITY_MODELS", "gemini-2.5-flash")

# ì½¤ë§ˆë¡œ ë¶„ë¦¬í•˜ì—¬ ë¦¬ìŠ¤íŠ¸ë¡œ ë§Œë“­ë‹ˆë‹¤.
FAST_MODEL_LIST = [m.strip() for m in FAST_MODELS_STR.split(',') if m.strip()]
QUALITY_MODEL_LIST = [m.strip() for m in QUALITY_MODELS_STR.split(',') if m.strip()]

# --- 2. Gemini ëª¨ë¸ ì„¤ì • ---
model_fast = None     # ë¹ ë¥¸ í”¼ë“œë°±ìš© ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤
model_quality = None  # ì¢…í•© ìš”ì•½ìš© ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤

# [ì‹ ê·œ] ê³µí†µ: ì‘ë‹µì„ ë¬´ì¡°ê±´ dictë¡œ ê°•ì œ
def _force_object(res: Any) -> Dict[str, Any]:
    """
    - dictë©´ ê·¸ëŒ€ë¡œ
    - listë©´ ì²« dictë¥¼ ì„ íƒ(ì—†ìœ¼ë©´ tipsë¡œ ê°ì‹¸ê¸°)
    - strë©´ JSON íŒŒì‹± ì‹œë„, ì‹¤íŒ¨ ì‹œ feedbackìœ¼ë¡œ ê°ì‹¸ê¸°
    - ê·¸ ì™¸ íƒ€ì…ì€ ë¬¸ìì—´í™”í•´ feedbackìœ¼ë¡œ ê°ì‹¸ê¸°
    """
    if res is None:
        return {}
    if isinstance(res, dict):
        return res
    if isinstance(res, list):
        for item in res:
            if isinstance(item, dict):
                return item
        return {"feedback": "AI í”¼ë“œë°± ìƒì„± ì‹¤íŒ¨", "tips": res}
    if isinstance(res, str):
        try:
            parsed = json.loads(res)
            return _force_object(parsed)
        except Exception:
            return {"feedback": res}
    # ê¸°íƒ€ íƒ€ì…
    return {"feedback": str(res)}

# [ì‹ ê·œ] ëª¨ë¸ ì´ˆê¸°í™” í—¬í¼ í•¨ìˆ˜
def initialize_model_from_list(
    model_list: List[str],
    generation_config: dict,
    safety_settings: list
) -> Optional[genai.GenerativeModel]:
    """
    ì œê³µëœ ëª¨ë¸ ì´ë¦„ ëª©ë¡ì„ ìˆœíšŒí•˜ë©°
    ê°€ì¥ ë¨¼ì € ì„±ê³µì ìœ¼ë¡œ ì´ˆê¸°í™”ë˜ëŠ” ëª¨ë¸ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    if not API_KEY:
        print("[ERROR] GOOGLE_API_KEYê°€ .env íŒŒì¼ì— ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return None

    for model_name in model_list:
        try:
            model = genai.GenerativeModel(
                model_name,
                safety_settings=safety_settings,
                generation_config=generation_config,
            )
            print(f"[INFO] ëª¨ë¸ ì´ˆê¸°í™” ì„±ê³µ: {model_name}")
            return model
        except Exception as e:
            print(f"[WARN] ëª¨ë¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {model_name} (ì˜¤ë¥˜: {e}). ë‹¤ìŒ ëª¨ë¸ì„ ì‹œë„í•©ë‹ˆë‹¤...")

    print(f"[ERROR] ëª©ë¡ì— ìˆëŠ” ëª¨ë¸ì„ ì´ˆê¸°í™”í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤: {model_list}")
    return None

# API í‚¤ê°€ ìˆì„ ê²½ìš°ì—ë§Œ ëª¨ë¸ ì„¤ì •ì„ ì‹œë„í•©ë‹ˆë‹¤.
if API_KEY:
    genai.configure(api_key=API_KEY)

    safety_settings = [
        {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_NONE"},
        {"category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_NONE"},
        {"category": "HARM_CATEGORY_SEXUALLY_EXPLICIT", "threshold": "BLOCK_NONE"},
        {"category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_NONE"},
    ]

    # JSON ì‘ë‹µì„ ìœ„í•œ ê³µí†µ ì„¤ì •
    generation_config = {
        "temperature": 0.7,
        "response_mime_type": "application/json",
    }

    print(f"[INFO] ë¹ ë¥¸ í”¼ë“œë°± ëª¨ë¸ ì´ˆê¸°í™” ì‹œë„ (ëª©ë¡: {FAST_MODEL_LIST})...")
    model_fast = initialize_model_from_list(
        FAST_MODEL_LIST, generation_config, safety_settings
    )

    print(f"[INFO] ì¢…í•© ìš”ì•½ ëª¨ë¸ ì´ˆê¸°í™” ì‹œë„ (ëª©ë¡: {QUALITY_MODEL_LIST})...")
    model_quality = initialize_model_from_list(
        QUALITY_MODEL_LIST, generation_config, safety_settings
    )
else:
    print("[ERROR] GOOGLE_API_KEYë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.")

# --- 3. AI í”¼ë“œë°± ìƒì„± í•¨ìˆ˜ ---

# [ìˆ˜ì •] get_conversational_feedback í•¨ìˆ˜ (extra_context í¬í•¨)
async def get_conversational_feedback(
    exercise_name: str,
    rep_counter: int,
    stage: str,
    body_profile: Optional[dict] = None,
    real_time_analysis: Optional[dict] = None,
    angle: Optional[float] = None,
    history: Optional[List[str]] = None,
    extra_context: Optional[dict] = None,  # ğŸ‘ˆ ì¶”ê°€ëœ íŒŒë¼ë¯¸í„°
) -> dict:
    """
    'ë¹ ë¥¸ í”¼ë“œë°±' ëª¨ë¸(model_fast)ì„ ì‚¬ìš©í•˜ì—¬ ì •í™•ë„ì™€ í”¼ë“œë°±ì„ JSONìœ¼ë¡œ ìš”ì²­í•©ë‹ˆë‹¤.
    (êµ¬ì¡°ëŠ” ìœ ì§€, ë‚´ë¶€ë§Œ ë³´ê°•)
    """
    if not model_fast:
        return {"accuracy": 0, "feedback": "âš ï¸ Gemini 'FAST' ëª¨ë¸ì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."}

    profile_section = f"* ì‚¬ìš©ìì˜ ì²´í˜• ë¶„ì„ ì •ë³´ (ì •ì  ë°ì´í„°):\n{body_profile}\n" if body_profile else ""
    analysis_section = f"* ì´ë²ˆ ì„¸íŠ¸ì˜ ì‹¤ì‹œê°„ ì›€ì§ì„/íˆìŠ¤í† ë¦¬ (ë™ì  ë°ì´í„°):\n{real_time_analysis}\n" if real_time_analysis else ""
    extra_section = f"* ì¶”ê°€ ë§¥ë½(í‘œì‹œëª…/ì„¸íŠ¸/íƒ€ê¹ƒ):\n{extra_context}\n" if extra_context else ""

    # í‘œì‹œìš© í•œê¸€ ì´ë¦„ ìš°ì„  ì‚¬ìš©
    disp = (extra_context or {}).get("exercise_display_name") or exercise_name
    set_idx = (extra_context or {}).get("set_index")
    total_sets = (extra_context or {}).get("total_sets")
    target_reps = (extra_context or {}).get("target_reps")

    # âš ï¸ ìµœìƒìœ„ëŠ” "ë°˜ë“œì‹œ ê°ì²´(Object)"ë¡œë§Œ, í‚¤ ì œí•œì„ ê°•í•˜ê²Œ ëª…ì‹œ
    prompt = f"""
ë‹¹ì‹ ì€ í•œêµ­ì–´ë¡œ ë‹µí•˜ëŠ” ì „ë¬¸ AI í¼ìŠ¤ë„ íŠ¸ë ˆì´ë„ˆì…ë‹ˆë‹¤.
ì•„ë˜ì˜ ì •ì /ë™ì /ì¶”ê°€ ë§¥ë½ì„ ì°¸ì¡°í•˜ë˜, ê·¸ëŒ€ë¡œ ë³µë¶™í•˜ì§€ ë§ê³  **ì¢…í•© íŒë‹¨**ì„ ì œê³µí•˜ì„¸ìš”.

{profile_section}
{analysis_section}
{extra_section}

* í˜„ì¬ ìš´ë™ ì •ë³´:
- ìš´ë™(í‘œì‹œëª…): {disp}
- ìš´ë™(ë‚´ë¶€ID): {exercise_name}
- ë‹¨ê³„: {stage}
- ë°˜ë³µ íšŸìˆ˜(ì‹¤í–‰): {rep_counter}
- ëª©í‘œ ë°˜ë³µìˆ˜(ì„¸íŠ¸ë‹¹): {target_reps}
- í˜„ì¬ ì„¸íŠ¸/ì´ ì„¸íŠ¸: {set_idx}/{total_sets}

* JSON ì¶œë ¥ ê·œì¹™(ìµœìƒìœ„ëŠ” **ë°˜ë“œì‹œ ê°ì²´(Object)ë¡œë§Œ**; ë°°ì—´ë¡œ ì‹œì‘ ê¸ˆì§€):
{{
  "accuracy": <0~100 ì •ìˆ˜>,
  "feedback": "<70ì ì´ë‚´ í•œêµ­ì–´ í•µì‹¬ ë¬¸ì¥>",
  "tips": ["ì§§ì€ íŒ1", "ì§§ì€ íŒ2"],
  "risk_level": "low" | "mid" | "high"
}}
í‚¤ëŠ” ìœ„ 4ê°œë§Œ í¬í•¨í•˜ê³ , ê·¸ ì™¸ í‚¤ëŠ” ìƒì„±í•˜ì§€ ë§ˆì„¸ìš”.
"""

    try:
        resp = await model_fast.generate_content_async(prompt)
        raw = resp.text
        result = _force_object(raw)

        # ê¸°ë³¸ê°’/íƒ€ì… ì •ë¦¬
        result.setdefault("accuracy", 0)
        result.setdefault("feedback", "AI í”¼ë“œë°± ìƒì„± ì‹¤íŒ¨")
        result.setdefault("tips", [])
        result.setdefault("risk_level", "unknown")
        if isinstance(result["tips"], str):
            result["tips"] = [result["tips"]]

        return result

    except Exception as e:
        print(f"--- GEMINI API ERROR (FAST) ---\nError: {e}\n--------------------------")
        if "resp" in locals() and hasattr(resp, "prompt_feedback"):
            print(f"Prompt Feedback: {resp.prompt_feedback}")
        return {"accuracy": 0, "feedback": "âš ï¸ AI í”¼ë“œë°± ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.", "tips": [], "risk_level": "unknown"}


async def get_overall_feedback(set_results: list[dict]) -> dict:
    """
    'ì¢…í•© ìš”ì•½' ëª¨ë¸(model_quality)ì„ ì‚¬ìš©í•˜ì—¬
    ì „ì²´ì ì¸ ìš´ë™ í’ˆì§ˆ, ìì„¸ ì•ˆì •ì„±, í–¥ìƒ í¬ì¸íŠ¸ë¥¼ ì¢…í•©ì ìœ¼ë¡œ í‰ê°€.
    (êµ¬ì¡°ëŠ” ìœ ì§€, ë‚´ë¶€ë§Œ ë³´ê°•)
    """
    if not model_quality:
        return {"overall_feedback": "âš ï¸ Gemini 'QUALITY' ëª¨ë¸ì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.", "summary_accuracy": 0, "improvement_tips": []}

    prompt = f"""
ë‹¹ì‹ ì€ í”¼íŠ¸ë‹ˆìŠ¤ ì „ë¬¸ê°€ AI íŠ¸ë ˆì´ë„ˆì…ë‹ˆë‹¤.
ì•„ë˜ëŠ” ì‚¬ìš©ìì˜ ê° ì„¸íŠ¸ë³„ ìš´ë™ ë¶„ì„ ê²°ê³¼ì…ë‹ˆë‹¤.
ì´ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì „ì²´ ìš´ë™ì— ëŒ€í•œ ì¢…í•© í”¼ë“œë°±ì„ ì‘ì„±í•˜ì„¸ìš”.

ë°ì´í„°:
{json.dumps(set_results, ensure_ascii=False, indent=2)}

ì‘ì„± ê·œì¹™:
1. ì „ì²´ì ì¸ ìš´ë™ ìˆ˜í–‰ í’ˆì§ˆì„ ìš”ì•½í•˜ì„¸ìš” (ì •í™•ë„, ì•ˆì •ì„±, í”¼ë¡œë„ ë“±).
2. ì‚¬ìš©ìì˜ ê°œì„ ì  2~3ê°€ì§€ë¥¼ ì§§ê³  ëª…í™•í•˜ê²Œ ì œì‹œí•˜ì„¸ìš”.
3. ë¬¸ì¥ì€ ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´ë¡œ ì‘ì„±í•˜ê³ , 200ì ì´ë‚´ë¡œ ë§ˆë¬´ë¦¬í•˜ì„¸ìš”.
4. ìµœìƒìœ„ëŠ” ë°˜ë“œì‹œ ê°ì²´(Object) JSONìœ¼ë¡œë§Œ ì¶œë ¥í•˜ê³ , ì•„ë˜ í‚¤ë§Œ í¬í•¨í•˜ì„¸ìš”:
{{
  "overall_feedback": "ë¬¸ì¥",
  "summary_accuracy": <í‰ê·  ì •í™•ë„(ìˆ«ì)>,
  "improvement_tips": ["tip1", "tip2"]
}}
"""

    try:
        resp = await model_quality.generate_content_async(prompt)
        raw = resp.text
        result = _force_object(raw)

        # ê¸°ë³¸ê°’/íƒ€ì… ì •ë¦¬
        result.setdefault("overall_feedback", "ì¢…í•© í”¼ë“œë°± ìƒì„± ì‹¤íŒ¨")
        result.setdefault("summary_accuracy", 0)
        result.setdefault("improvement_tips", [])
        if isinstance(result["improvement_tips"], str):
            result["improvement_tips"] = [result["improvement_tips"]]

        return result

    except Exception as e:
        print(f"--- GEMINI API ERROR (QUALITY) ---\nError: {e}\n--------------------------")
        if "resp" in locals() and hasattr(resp, "prompt_feedback"):
            print(f"Prompt Feedback: {resp.prompt_feedback}")
        return {"overall_feedback": "âš ï¸ ì¢…í•© í”¼ë“œë°± ìƒì„± ì‹¤íŒ¨", "summary_accuracy": 0, "improvement_tips": []}
