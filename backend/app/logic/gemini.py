import os
import json
from typing import Optional, List, Any, Dict
from dotenv import load_dotenv
import google.generativeai as genai

# --- 1. í™˜ê²½ ì„¤ì • ---
load_dotenv()
API_KEY = os.getenv("GOOGLE_API_KEY")

# ëª¨ë¸ ëª©ë¡ í™˜ê²½ ë³€ìˆ˜
FAST_MODELS_STR = os.getenv("GEMINI_FAST_MODELS", "gemini-2.5-flash")
QUALITY_MODELS_STR = os.getenv("GEMINI_QUALITY_MODELS", "gemini-2.5-flash")

FAST_MODEL_LIST = [m.strip() for m in FAST_MODELS_STR.split(',') if m.strip()]
QUALITY_MODEL_LIST = [m.strip() for m in QUALITY_MODELS_STR.split(',') if m.strip()]

# --- 2. Gemini ëª¨ë¸ ì„¤ì • ---
model_fast = None     # ë¹ ë¥¸ í”¼ë“œë°±
model_quality = None  # ì¢…í•© ìš”ì•½

# ===== (A) ê³µí†µ: í† í°/ì¶œë ¥ ìµœì†Œí™” ì„¤ì • =====
BASE_GENERATION_CONFIG = {
    "temperature": 0.5,
    "top_p": 0.9,
    "top_k": 40,
    "candidate_count": 1,
    "response_mime_type": "application/json",
    "max_output_tokens": 256,   # ì¶œë ¥ ê¸¸ì´ ì œí•œ
}

# system instruction: ë§¤ í˜¸ì¶œë§ˆë‹¤ ì¥ë¬¸ ê·œì¹™ì„ ë„£ì§€ ì•Šê¸° ìœ„í•´ ê³ ì •
FAST_SYSTEM_INSTRUCTION = (
    "ë‹¹ì‹ ì€ í•œêµ­ì–´ë¡œ ë‹µí•˜ëŠ” AI í¼ìŠ¤ë„ íŠ¸ë ˆì´ë„ˆì…ë‹ˆë‹¤. "
    "ì…ë ¥ JSONë§Œ ë³´ê³  í•µì‹¬ë§Œ íŒë‹¨í•˜ë©°, ë°˜ë“œì‹œ JSONìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”."
)

QUALITY_SYSTEM_INSTRUCTION = (
    "ë‹¹ì‹ ì€ í”¼íŠ¸ë‹ˆìŠ¤ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì…ë ¥ JSON(ì„¸íŠ¸ë³„ ê²°ê³¼ ìš”ì•½)ë§Œ ë³´ê³  "
    "200ì ì´ë‚´ í•œêµ­ì–´ë¡œ ì¢…í•© í”¼ë“œë°±ì„ JSONìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”."
)

# ì´ íŒŒì¼ ë‚´ì—ì„œ ë™ì ìœ¼ë¡œ ë°”ê¿” ë¼ìš¸ ì „ì—­ ì§€ì‹œë¬¸
_SYSTEM_INSTRUCTION: str = ""

# [ì‹ ê·œ] ì…ë ¥ ì¶•ì†Œ ìœ í‹¸: ìˆ«ì ë°˜ì˜¬ë¦¼/ê¸´ í…ìŠ¤íŠ¸ ìë¥´ê¸°
def _round_num(v: Any, nd: int = 3) -> Any:
    if isinstance(v, float):
        return round(v, nd)
    if isinstance(v, list):
        return [_round_num(x, nd) for x in v]
    if isinstance(v, dict):
        return {k: _round_num(v[k], nd) for k in v}
    return v

def _truncate_str(s: Any, maxlen: int = 200) -> Any:
    if isinstance(s, str) and len(s) > maxlen:
        return s[:maxlen] + "â€¦"
    return s

def _compact_set_item(item: Dict[str, Any]) -> Dict[str, Any]:
    """ì„¸íŠ¸ ê²°ê³¼ì—ì„œ ê±°ëŒ€ í•„ë“œ ì œê±° ë° ìµœì†Œ ìš”ì•½ë§Œ ë‚¨ê¹€"""
    meta = item.get("meta") or {}
    stats = item.get("stats") or {}
    # accuracy/ì¹¼ë¡œë¦¬/ì‹œê°„ ë“±ë§Œ ë‚¨ê¸°ê³  ìˆ«ìëŠ” ë°˜ì˜¬ë¦¼
    compact_stats = {
        "accuracy": stats.get("accuracy"),
        "calories": stats.get("calories"),
        "avg_speed": stats.get("avg_speed"),
        "tempo": stats.get("tempo"),
    }
    compact_stats = _round_num(compact_stats, 3)

    # ê¸¸ ìˆ˜ ìˆëŠ” í…ìŠ¤íŠ¸ëŠ” ì˜ë¼ì¤Œ
    ai_feedback = _truncate_str(item.get("aiFeedback", ""), 180)

    # ì ˆëŒ€ ê¸ˆì§€: analysisData, landmarkHistory ê°™ì€ ì´ˆëŒ€í˜• í•„ë“œ
    return {
        "meta": {
            "setIndex": meta.get("setIndex"),
            "totalSets": meta.get("totalSets"),
            "targetReps": meta.get("targetReps"),
            "exerciseId": meta.get("exerciseId"),
            "exerciseName": meta.get("exerciseName"),
        },
        "stats": compact_stats,
        "aiFeedback": ai_feedback,
        # í•„ìš”í•œ ê²½ìš° ê°„ë‹¨í•œ ê·œì¹™ì„± íƒœê·¸ ì •ë„ë§Œ ìœ ì§€í•  ìˆ˜ ìˆìŒ
    }

def _compact_set_results(set_results: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    # ê¸¸ë©´ ìµœê·¼ Nê°œë§Œ, ë˜ëŠ” ì „ë¶€ ì–•ê²Œ: ì—¬ê¸°ì„œëŠ” ì „ë¶€ ì–•ê²Œ + ìµœëŒ€ 12ì„¸íŠ¸ê¹Œì§€ë§Œ
    MAX_SETS = 12
    compact = []
    for i, it in enumerate(set_results[:MAX_SETS]):
        compact.append(_compact_set_item(it))
    return compact

# [ì‹ ê·œ] ëª¨ë¸ ì´ˆê¸°í™” í—¬í¼ (system_instruction ì£¼ì… + generation_config ì‚¬ìš©)
def initialize_model_from_list(
    model_list: List[str],
    generation_config: dict,
    safety_settings: list
) -> Optional[genai.GenerativeModel]:
    if not API_KEY:
        print("[ERROR] GOOGLE_API_KEYê°€ .env íŒŒì¼ì— ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return None
    for model_name in model_list:
        try:
            model = genai.GenerativeModel(
                model_name,
                safety_settings=safety_settings,
                generation_config=generation_config,
                system_instruction=_SYSTEM_INSTRUCTION,  # ğŸ‘ˆ ê³ ì • ì§€ì‹œ
            )
            print(f"[INFO] ëª¨ë¸ ì´ˆê¸°í™” ì„±ê³µ: {model_name}")
            return model
        except Exception as e:
            print(f"[WARN] ëª¨ë¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {model_name} (ì˜¤ë¥˜: {e}). ë‹¤ìŒ ëª¨ë¸ì„ ì‹œë„í•©ë‹ˆë‹¤...")
    print(f"[ERROR] ëª©ë¡ì— ìˆëŠ” ëª¨ë¸ì„ ì´ˆê¸°í™”í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤: {model_list}")
    return None

# API í‚¤ ì„¤ì • ë° ëª¨ë¸ ì¤€ë¹„
if API_KEY:
    genai.configure(api_key=API_KEY)

    safety_settings = [
        {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_NONE"},
        {"category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_NONE"},
        {"category": "HARM_CATEGORY_SEXUALLY_EXPLICIT", "threshold": "BLOCK_NONE"},
        {"category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_NONE"},
    ]

    # ë¹ ë¥¸ í”¼ë“œë°± ëª¨ë¸
    print(f"[INFO] ë¹ ë¥¸ í”¼ë“œë°± ëª¨ë¸ ì´ˆê¸°í™” ì‹œë„ (ëª©ë¡: {FAST_MODEL_LIST})...")
    _SYSTEM_INSTRUCTION = FAST_SYSTEM_INSTRUCTION
    model_fast = initialize_model_from_list(
        FAST_MODEL_LIST, BASE_GENERATION_CONFIG, safety_settings
    )

    # ì¢…í•© ìš”ì•½ ëª¨ë¸
    print(f"[INFO] ì¢…í•© ìš”ì•½ ëª¨ë¸ ì´ˆê¸°í™” ì‹œë„ (ëª©ë¡: {QUALITY_MODEL_LIST})...")
    _SYSTEM_INSTRUCTION = QUALITY_SYSTEM_INSTRUCTION
    model_quality = initialize_model_from_list(
        QUALITY_MODEL_LIST, BASE_GENERATION_CONFIG, safety_settings
    )
else:
    print("[ERROR] GOOGLE_API_KEYë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.")


# --- 3. AI í”¼ë“œë°± ìƒì„± í•¨ìˆ˜ ---

# (1) ë¹ ë¥¸ í”¼ë“œë°±
async def get_conversational_feedback(
    exercise_name: str,
    rep_counter: int,
    stage: str,
    body_profile: Optional[dict] = None,
    real_time_analysis: Optional[dict] = None,
    angle: Optional[float] = None,
    history: Optional[List[str]] = None,
    extra_context: Optional[dict] = None,
) -> dict:
    """
    'ë¹ ë¥¸ í”¼ë“œë°±' ëª¨ë¸(model_fast)ì„ ì‚¬ìš©í•˜ì—¬ ì •í™•ë„ì™€ í”¼ë“œë°±ì„ JSONìœ¼ë¡œ ìš”ì²­í•©ë‹ˆë‹¤.
    """
    if not model_fast:
        return {"accuracy": 0, "feedback": "âš ï¸ Gemini 'FAST' ëª¨ë¸ì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."}

    # âœ… í”„ë¡¬í”„íŠ¸ë¥¼ ì¥ë¬¸ ê·œì¹™ ì—†ì´ 'ë°ì´í„° JSON'ë§Œ ë³´ë‚´ë„ë¡ ì¶•ì†Œ
    disp = (extra_context or {}).get("exercise_display_name") or exercise_name
    payload = {
        "exercise_display_name": disp,
        "exercise_id": exercise_name,
        "stage": stage,
        "rep_counter": rep_counter,
        "target_reps": (extra_context or {}).get("target_reps"),
        "set": {
            "index": (extra_context or {}).get("set_index"),
            "total": (extra_context or {}).get("total_sets"),
        },
        # í° ë°ì´í„°ëŠ” ìŠ¬ë¦¼í™”
        "user_profile": _round_num(body_profile, 3) if body_profile else None,
        "realtime_summary": _round_num(real_time_analysis, 3) if real_time_analysis else None,
        "angle_sample": _round_num(angle, 3) if angle is not None else None,
        # íˆìŠ¤í† ë¦¬ëŠ” ìµœê·¼ Nê°œë§Œ (ê³¼ë„í•œ í…ìŠ¤íŠ¸ ë°©ì§€)
        "history_tail": history[-20:] if history and len(history) > 20 else history,
    }

    # ê³µë°± ì œê±°í•˜ì—¬ í† í° ì ˆì•½
    prompt = json.dumps(payload, ensure_ascii=False, separators=(",", ":"))

    try:
        resp = await model_fast.generate_content_async(prompt)
        try:
            return json.loads(resp.text)
        except Exception:
            print(f"[WARN] Gemini ì‘ë‹µì´ JSON í˜•ì‹ì´ ì•„ë‹˜: {resp.text}")
            return {"accuracy": 0, "feedback": "âš ï¸ AI ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨"}
    except Exception as e:
        print(f"--- GEMINI API ERROR (FAST) ---\nError: {e}\n--------------------------")
        if "resp" in locals() and hasattr(resp, "prompt_feedback"):
            print(f"Prompt Feedback: {resp.prompt_feedback}")
        return {"accuracy": 0, "feedback": "âš ï¸ AI í”¼ë“œë°± ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."}

# (2) ì¢…í•© í”¼ë“œë°±
async def get_overall_feedback(set_results: list[dict]) -> dict:
    """
    'ì¢…í•© ìš”ì•½' ëª¨ë¸(model_quality)ì„ ì‚¬ìš©í•˜ì—¬ ìš´ë™ ì „ì²´ì— ëŒ€í•œ ìš”ì•½/ê°œì„  í¬ì¸íŠ¸ë¥¼ ìƒì„±.
    """
    if not model_quality:
        return {"overall_feedback": "âš ï¸ Gemini 'QUALITY' ëª¨ë¸ì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."}

    # âœ… ì…ë ¥ ì¶•ì†Œ: ê±°ëŒ€ í•„ë“œ ì œê±° + ìˆ«ì ë°˜ì˜¬ë¦¼ + ìµœê·¼ Nì„¸íŠ¸ ì œí•œ
    compact_sets = _compact_set_results(set_results)

    payload = {
        "sets": compact_sets,
        # í‰ê·  ì •í™•ë„(ìˆìœ¼ë©´) í”„ë¦¬ì»´í“¨íŠ¸í•´ì„œ íŒíŠ¸ ì œê³µ â†’ ëª¨ë¸ ì¶”ë¡  ë¶€ë‹´ ê°ì†Œ
        "avg_accuracy_hint": _round_num(
            sum([(s.get("stats") or {}).get("accuracy", 0) or 0 for s in compact_sets]) / max(len(compact_sets), 1), 2
        ) if compact_sets else 0.0
    }

    prompt = json.dumps(payload, ensure_ascii=False, separators=(",", ":"))

    try:
        resp = await model_quality.generate_content_async(prompt)
        return json.loads(resp.text)
    except Exception as e:
        print(f"--- GEMINI API ERROR (QUALITY) ---\nError: {e}\n--------------------------")
        if "resp" in locals() and hasattr(resp, "prompt_feedback"):
            print(f"Prompt Feedback: {resp.prompt_feedback}")
        return {"overall_feedback": "âš ï¸ ì¢…í•© í”¼ë“œë°± ìƒì„± ì‹¤íŒ¨"}
